# -*- coding: utf-8 -*-
"""OCR

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s3ytmLlEs-X9_dDId5fNCvCp-UGzD8cy
"""

try:
  from enum import Enum
  import json
  import random
  import io
  import ast
  from PIL import Image, ImageDraw, ImageFont
  from PIL import ImageColor
  from IPython.display import Markdown, display
  from io import BytesIO
  from PIL import Image
  from openai import OpenAI
  import os
  import base64
  import glob
  import os
  import torch
  from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
  import PIL.Image
  import torch
  import numpy as np
  import streamlit as st
except Exception as e:
  print(e)

STYLE = """
<style>
img {
    max-width: 100%;
}
</style>
"""
# Clear GPU cache
torch.cuda.empty_cache()

# Streamlit UI
st.set_page_config(page_title="OCR", layout="centered")

#st.title("white[Text to Image Generator]")
st.title(":rainbow[OCR]")




def set_bg_hack(main_bg):
    '''
    A function to unpack an image from root folder and set as bg.

    Returns
    -------
    The background.
    '''
    # set bg name
    main_bg_ext = "png"

    st.markdown(
         f"""
         <style>
         .stApp {{
             background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, "rb").read()).decode()});
             background-size: cover
         }}
         </style>
         """,
         unsafe_allow_html=True
     )




def inference(image_path, prompt, sys_prompt="You are a helpful assistant.", max_new_tokens=4096, return_input=False):
    checkpoint = "Qwen/Qwen2.5-VL-7B-Instruct"
    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(checkpoint, torch_dtype=torch.bfloat16, attn_implementation="flash_attention_2",device_map="auto")
    processor = AutoProcessor.from_pretrained(checkpoint)
    image = Image.open(image_path)
    image_local_path = "file://" + image_path
    messages = [
        {"role": "system", "content": sys_prompt},
        {"role": "user", "content": [
                {"type": "text", "text": prompt},
                {"image": image_local_path},
            ]
        },
    ]
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    print("text:", text)
    # image_inputs, video_inputs = process_vision_info([messages])
    inputs = processor(text=[text], images=[image], padding=True, return_tensors="pt")
    inputs = inputs.to('cuda')

    output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)
    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]
    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)
    if return_input:
        return output_text[0], inputs
    else:
        return output_text[0]




def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")




def OCR(input_prompts):
  global_path = os.getcwd()
  image_path = f"{global_path}/test.jpg"
  image = Image.open(image_path)
  response = inference(image_path, input_prompts)
  st.text_area(label ="",value=response, height =100)





class FileUpload(object):
  def __init__(self):
    self.fileTypes = ["png", "jpg", "jpeg"]
  def run_image(self):
    """
    Upload File on Streamlit Code
    :return:
    """
    file = st.file_uploader("Upload file", type=self.fileTypes)
    show_file = st.empty()
    if not file:
      show_file.info("Please upload a file of type: " + ", ".join(["png", "jpg", "jpeg"]))
      return
    content = file.getvalue()
    with open("test.jpg", "wb") as f:
      f.write(content)
    if isinstance(file, BytesIO):
      show_file.image(file)


# Selectbox
set_bg_hack('/home/avidmech/Image_Generation_DeepSeek_1B pro/Janus/get.png')
option = st.selectbox(':blue[What do you want to do?]',['OCR'])
if option == "OCR":
  text_input = st.text_input(":blue[Text Prompt:]")
  upload = FileUpload()
  upload.run_image()
  if st.button("Run"):
    OCR(text_input)
